{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"GENOCIDE: Trump is inviting South African farmers with families that are being targeted based on the color of their skin to come to America. \" + \"Elon Musk reposted\"  \n",
    "texto+=\"Starlink\" \n",
    "texto+=\"@Starlink\" \n",
    "texto+=\"Connect to high-speed internet onboard \" \n",
    "texto+=\"@United\"  \n",
    "texto+=\" flights from gate to gate üõ∞Ô∏è‚úàÔ∏è\" \n",
    "texto+=\"Quote\" \n",
    "texto+=\"United Airlines\" \n",
    "texto+=\"@united\" \n",
    "texto+=\"The world's fastest, most reliable Wi-Fi in the sky, @Starlink, has officially landed on our first aircraft, with the rest of our fleet to follow.\" \n",
    "texto+=\"That means you'll be able to stream, browse and game just like you do at home. And the icing on the digital cake? Starlink will be\" \n",
    "texto+=\"Show more\" \n",
    "texto+=\"0:00 / 0:34\" \n",
    "texto+=\"Elon Musk\" \n",
    "texto+=\"@elonmusk\" \n",
    "texto+=\"Starlink starting on \" \n",
    "texto+=\"@United\" \n",
    "texto+=\" Airlines!\" \n",
    "texto+=\"Quote\" \n",
    "texto+=\"United Airlines\" \n",
    "texto+=\"@united\" \n",
    "texto+=\"The world's fastest, most reliable Wi-Fi in the sky, @Starlink, has officially landed on our first aircraft, with the rest of our fleet to follow.\" \n",
    "texto+=\"That means you'll be able to stream, browse and game just like you do at home. And the icing on the digital cake? Starlink will be\" \n",
    "texto+=\"Show more\" \n",
    "texto+=\"How do satellites aid Starlink aviation?\" \n",
    "texto+=\"How does Musk‚Äôs role affect rollout?\" \n",
    "texto+=\"Elon Musk\" \n",
    "texto+=\"Quote\" \n",
    "texto+=\"Ian Miles Cheong\" \n",
    "texto+=\"Someone needs to write a serious study on how video game fandom got taken over by people infected with the woke mind virus and people who hate Elon Musk and Donald Trump. \" \n",
    "texto+=\"Pretty much every gaming publication, all of Reddit and even a number of YouTubers who cover these games\" \n",
    "texto+=\"Show more\" \n",
    "texto+=\"Elon Musk reposted\" \n",
    "texto+=\"DogeDesigner\" \n",
    "texto+=\"Millions in South Africa could benefit from Starlink, but it‚Äôs not allowed just because Elon Musk isn‚Äôt black. This is an injustice to millions who need better internet. Absolutely disgraceful.\" \n",
    "texto+=\"0:01 / 0:14\" \n",
    "texto+=\"Elon Musk\" \n",
    "texto+=\"Wow\" \n",
    "texto+=\"Quote\" \n",
    "texto+=\"Eric Daugherty\" \n",
    "texto+=\"@EricLDaugh\" \n",
    "texto+=\"üö® NEW: The Trump administration's DHS has just ended collective bargaining for TSA officers.\" \n",
    "texto+=\"DHS says, shockingly, TSA had more people doing 'full-time union work' than actually performing security functions at 86% of airports.\" \n",
    "texto+=\"Plus, 60% of 'poor performers' were allowed to\" \n",
    "texto+=\"Show more\" \n",
    "texto+=\"Elon Musk\" \n",
    "texto+=\"@elonmusk\" \n",
    "texto+=\"You‚Äôre welcome. \" \n",
    "texto+=\"Thankfully, this administration cares about all people.\" \n",
    "texto+=\"Quote\" \n",
    "texto+=\"Visegr√°d 24\" \n",
    "texto+=\"@visegrad24\" \n",
    "texto+=\"Thanks to the hard work of South African activists, commentators and citizen journalists, the truth about the racism, violence and gross mismanagement of South Africa has come to light‚Ä¶\" \n",
    "texto+=\"Thank you to Elon Musk for giving so many previously voiceless people a platform on ùïè!\" \n",
    "texto+=\"Show more\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"data/losmiserables.txt\", \"r\")\n",
    "texto = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Funci√≥n para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    # Convertir a min√∫sculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Eliminar acentos\n",
    "    texto = re.sub(r'[√°√†√§√¢]', 'a', texto)\n",
    "    texto = re.sub(r'[√©√®√´√™]', 'e', texto)\n",
    "    texto = re.sub(r'[√≠√¨√Ø√Æ]', 'i', texto)\n",
    "    texto = re.sub(r'[√≥√≤√∂√¥]', 'o', texto)\n",
    "    texto = re.sub(r'[√∫√π√º√ª]', 'u', texto)\n",
    "    texto = re.sub(r'[√Ω]', 'y', texto)\n",
    "    texto = re.sub(r'[√±]', 'n', texto)\n",
    "    \n",
    "    # Eliminar caracteres especiales y n√∫meros, dejando solo letras y espacios\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto)\n",
    "    \n",
    "    return texto\n",
    "\n",
    "# Aplicar la limpieza al texto\n",
    "texto = limpiar_texto(texto)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras:335\n",
      "Total de palabras no repetidas:194\n",
      "Frecuencia de palabras:\n",
      "'genocide': 1\n",
      "'trump': 3\n",
      "'is': 2\n",
      "'inviting': 1\n",
      "'south': 4\n",
      "'african': 2\n",
      "'farmers': 1\n",
      "'with': 4\n",
      "'families': 1\n",
      "'that': 1\n",
      "'are': 1\n",
      "'being': 1\n",
      "'targeted': 1\n",
      "'based': 1\n",
      "'on': 8\n",
      "'the': 14\n",
      "'color': 1\n",
      "'of': 9\n",
      "'their': 1\n",
      "'skin': 1\n",
      "'to': 13\n",
      "'come': 2\n",
      "'america': 1\n",
      "'elon': 6\n",
      "'musk': 5\n",
      "'repostedstarlinkstarlinkconnect': 1\n",
      "'highspeed': 1\n",
      "'internet': 2\n",
      "'onboard': 1\n",
      "'united': 2\n",
      "'flights': 1\n",
      "'from': 2\n",
      "'gate': 2\n",
      "'quoteunited': 1\n",
      "'airlinesunitedthe': 2\n",
      "'worlds': 2\n",
      "'fastest': 2\n",
      "'most': 2\n",
      "'reliable': 2\n",
      "'wifi': 2\n",
      "'in': 3\n",
      "'sky': 2\n",
      "'starlink': 6\n",
      "'has': 4\n",
      "'officially': 2\n",
      "'landed': 2\n",
      "'our': 4\n",
      "'first': 2\n",
      "'aircraft': 2\n",
      "'rest': 2\n",
      "'fleet': 2\n",
      "'followthat': 2\n",
      "'means': 2\n",
      "'youll': 2\n",
      "'be': 2\n",
      "'able': 2\n",
      "'stream': 2\n",
      "'browse': 2\n",
      "'and': 9\n",
      "'game': 3\n",
      "'just': 4\n",
      "'like': 2\n",
      "'you': 3\n",
      "'do': 3\n",
      "'at': 3\n",
      "'home': 2\n",
      "'icing': 2\n",
      "'digital': 2\n",
      "'cake': 2\n",
      "'will': 2\n",
      "'beshow': 2\n",
      "'more': 3\n",
      "'muskelonmuskstarlink': 1\n",
      "'starting': 1\n",
      "'airlinesquoteunited': 1\n",
      "'morehow': 1\n",
      "'satellites': 1\n",
      "'aid': 1\n",
      "'aviationhow': 1\n",
      "'does': 1\n",
      "'musks': 1\n",
      "'role': 1\n",
      "'affect': 1\n",
      "'rolloutelon': 1\n",
      "'muskquoteian': 1\n",
      "'miles': 1\n",
      "'cheongsomeone': 1\n",
      "'needs': 1\n",
      "'write': 1\n",
      "'a': 3\n",
      "'serious': 1\n",
      "'study': 1\n",
      "'how': 1\n",
      "'video': 1\n",
      "'fandom': 1\n",
      "'got': 1\n",
      "'taken': 1\n",
      "'over': 1\n",
      "'by': 1\n",
      "'people': 4\n",
      "'infected': 1\n",
      "'woke': 1\n",
      "'mind': 1\n",
      "'virus': 1\n",
      "'who': 3\n",
      "'hate': 1\n",
      "'donald': 1\n",
      "'pretty': 1\n",
      "'much': 1\n",
      "'every': 1\n",
      "'gaming': 1\n",
      "'publication': 1\n",
      "'all': 2\n",
      "'reddit': 1\n",
      "'even': 1\n",
      "'number': 1\n",
      "'youtubers': 1\n",
      "'cover': 1\n",
      "'these': 1\n",
      "'gamesshow': 1\n",
      "'moreelon': 2\n",
      "'reposteddogedesignermillions': 1\n",
      "'africa': 2\n",
      "'could': 1\n",
      "'benefit': 1\n",
      "'but': 1\n",
      "'its': 1\n",
      "'not': 1\n",
      "'allowed': 2\n",
      "'because': 1\n",
      "'isnt': 1\n",
      "'black': 1\n",
      "'this': 2\n",
      "'an': 1\n",
      "'injustice': 1\n",
      "'millions': 1\n",
      "'need': 1\n",
      "'better': 1\n",
      "'absolutely': 1\n",
      "'disgraceful': 1\n",
      "'muskwowquoteeric': 1\n",
      "'daughertyericldaugh': 1\n",
      "'new': 1\n",
      "'administrations': 1\n",
      "'dhs': 1\n",
      "'ended': 1\n",
      "'collective': 1\n",
      "'bargaining': 1\n",
      "'for': 2\n",
      "'tsa': 2\n",
      "'officersdhs': 1\n",
      "'says': 1\n",
      "'shockingly': 1\n",
      "'had': 1\n",
      "'doing': 1\n",
      "'fulltime': 1\n",
      "'union': 1\n",
      "'work': 2\n",
      "'than': 1\n",
      "'actually': 1\n",
      "'performing': 1\n",
      "'security': 1\n",
      "'functions': 1\n",
      "'airportsplus': 1\n",
      "'poor': 1\n",
      "'performers': 1\n",
      "'were': 1\n",
      "'toshow': 1\n",
      "'muskelonmuskyoure': 1\n",
      "'welcome': 1\n",
      "'thankfully': 1\n",
      "'administration': 1\n",
      "'cares': 1\n",
      "'about': 2\n",
      "'peoplequotevisegrad': 1\n",
      "'visegradthanks': 1\n",
      "'hard': 1\n",
      "'activists': 1\n",
      "'commentators': 1\n",
      "'citizen': 1\n",
      "'journalists': 1\n",
      "'truth': 1\n",
      "'racism': 1\n",
      "'violence': 1\n",
      "'gross': 1\n",
      "'mismanagement': 1\n",
      "'lightthank': 1\n",
      "'giving': 1\n",
      "'so': 1\n",
      "'many': 1\n",
      "'previously': 1\n",
      "'voiceless': 1\n",
      "'platform': 1\n",
      "'show': 1\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar las palabras y sus frecuencias\n",
    "palabras = limpiar_texto(texto).split()\n",
    "\n",
    "frecuencia_palabras = {}\n",
    "#frecuencia_palabras = np.zeros()\n",
    "#   palabras = texto.lower().split()\n",
    "# Recorrer cada l√≠nea del texto\n",
    "for palabra in palabras:\n",
    "    # Dividir la l√≠nea en palabras\n",
    "    #palabras = linea.lower().split()\n",
    "    #print(palabra)\n",
    "    #Contar frecuencia de cada palabra\n",
    "    #for palabra in palabras:\n",
    "    if palabra in frecuencia_palabras:\n",
    "        frecuencia_palabras[palabra] += 1\n",
    "    else:\n",
    "        frecuencia_palabras[palabra] = 1\n",
    "\n",
    "# Mostrar el diccionario resultante\n",
    "print(\"Total de palabras:\" + str(len(palabras)))\n",
    "print(\"Total de palabras no repetidas:\" + str(len(set(frecuencia_palabras))))\n",
    "print(\"Frecuencia de palabras:\")\n",
    "for palabra, frecuencia in frecuencia_palabras.items():\n",
    "    print(f\"'{palabra}': {frecuencia}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frecuencia_palabras['aquellas'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 14), ('to', 13), ('of', 9), ('and', 9), ('on', 8), ('elon', 6), ('starlink', 6), ('musk', 5), ('south', 4), ('with', 4), ('has', 4), ('our', 4), ('just', 4), ('people', 4), ('trump', 3), ('in', 3), ('game', 3), ('you', 3), ('do', 3), ('at', 3), ('more', 3), ('a', 3), ('who', 3), ('is', 2), ('african', 2), ('come', 2), ('internet', 2), ('united', 2), ('from', 2), ('gate', 2), ('airlinesunitedthe', 2), ('worlds', 2), ('fastest', 2), ('most', 2), ('reliable', 2), ('wifi', 2), ('sky', 2), ('officially', 2), ('landed', 2), ('first', 2), ('aircraft', 2), ('rest', 2), ('fleet', 2), ('followthat', 2), ('means', 2), ('youll', 2), ('be', 2), ('able', 2), ('stream', 2), ('browse', 2), ('like', 2), ('home', 2), ('icing', 2), ('digital', 2), ('cake', 2), ('will', 2), ('beshow', 2), ('all', 2), ('moreelon', 2), ('africa', 2), ('allowed', 2), ('this', 2), ('for', 2), ('tsa', 2), ('work', 2), ('about', 2), ('genocide', 1), ('inviting', 1), ('farmers', 1), ('families', 1), ('that', 1), ('are', 1), ('being', 1), ('targeted', 1), ('based', 1), ('color', 1), ('their', 1), ('skin', 1), ('america', 1), ('repostedstarlinkstarlinkconnect', 1), ('highspeed', 1), ('onboard', 1), ('flights', 1), ('quoteunited', 1), ('muskelonmuskstarlink', 1), ('starting', 1), ('airlinesquoteunited', 1), ('morehow', 1), ('satellites', 1), ('aid', 1), ('aviationhow', 1), ('does', 1), ('musks', 1), ('role', 1), ('affect', 1), ('rolloutelon', 1), ('muskquoteian', 1), ('miles', 1), ('cheongsomeone', 1), ('needs', 1), ('write', 1), ('serious', 1), ('study', 1), ('how', 1), ('video', 1), ('fandom', 1), ('got', 1), ('taken', 1), ('over', 1), ('by', 1), ('infected', 1), ('woke', 1), ('mind', 1), ('virus', 1), ('hate', 1), ('donald', 1), ('pretty', 1), ('much', 1), ('every', 1), ('gaming', 1), ('publication', 1), ('reddit', 1), ('even', 1), ('number', 1), ('youtubers', 1), ('cover', 1), ('these', 1), ('gamesshow', 1), ('reposteddogedesignermillions', 1), ('could', 1), ('benefit', 1), ('but', 1), ('its', 1), ('not', 1), ('because', 1), ('isnt', 1), ('black', 1), ('an', 1), ('injustice', 1), ('millions', 1), ('need', 1), ('better', 1), ('absolutely', 1), ('disgraceful', 1), ('muskwowquoteeric', 1), ('daughertyericldaugh', 1), ('new', 1), ('administrations', 1), ('dhs', 1), ('ended', 1), ('collective', 1), ('bargaining', 1), ('officersdhs', 1), ('says', 1), ('shockingly', 1), ('had', 1), ('doing', 1), ('fulltime', 1), ('union', 1), ('than', 1), ('actually', 1), ('performing', 1), ('security', 1), ('functions', 1), ('airportsplus', 1), ('poor', 1), ('performers', 1), ('were', 1), ('toshow', 1), ('muskelonmuskyoure', 1), ('welcome', 1), ('thankfully', 1), ('administration', 1), ('cares', 1), ('peoplequotevisegrad', 1), ('visegradthanks', 1), ('hard', 1), ('activists', 1), ('commentators', 1), ('citizen', 1), ('journalists', 1), ('truth', 1), ('racism', 1), ('violence', 1), ('gross', 1), ('mismanagement', 1), ('lightthank', 1), ('giving', 1), ('so', 1), ('many', 1), ('previously', 1), ('voiceless', 1), ('platform', 1), ('show', 1)]\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "#Ordena alfabeticamente\n",
    "#valores_ord = {k: v for k, v in sorted(frecuencia_palabras.items())}\n",
    "#print(valores_ord)\n",
    "# Ordena por frecuencia\n",
    "valores_ord = sorted(frecuencia_palabras.items(), key=operator.itemgetter(1), reverse=True)\n",
    "print(valores_ord)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
