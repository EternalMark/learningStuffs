{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Challenge\n",
    "\n",
    "* Get the book “Los Miserables” by Victor Hugo, from Carlos Slim Foundation: https://aprende.org/pruebat?sectionId=6\n",
    "* Convert the book into text (csv)\n",
    "* Clean the csv file\n",
    "  * Standardize (no upper chars, no whitespace, no punctuation, accents, if possible)\n",
    "  * Create a vocabulary with the words in the book, following the ideas when we discussed how to create a vocabulary in the slides (7..14) of this presentation.\n",
    "  * Store the vocabulary on disk in parquet format\n",
    "  * Do statistics, including\n",
    "   * How many words in original text (book)\n",
    "   * How many different words in vocabulary\n",
    "   * Print the 100 most frequent words in vocabulary\n",
    "   * Print the 100 least frequent words in vocabulary\n",
    "* Produce a 2 page report to describe your experience, methods, etc.\n",
    "* Write code in the language of your choice from this set (Go, Julia, Python)\n",
    "* Assigned: 03/08/2025\n",
    "* Deadline: 03/14/2025 @ 04:00 PM CDMX Time, using the Github page :\n",
    "* https://github.com/camachojua/diplomado-ia/tree/main/python/src/student_submissions/Vocabulary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  \n",
    "import re  #libreria para generar expresiones regulares\n",
    "import operator #libreria para ordenar listas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abrir el archivo con el contenido del libro los miserable, \n",
    "# previamente el pdf se convirtio a texto mediante una herramienta externa\n",
    "f = open(\"./data/Los-miserables.csv\", \"r\")\n",
    "texto = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para limpiar el texto\n",
    "def limpiar_texto(texto):\n",
    "    # Convertir a minúsculas\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    # Eliminar acentos\n",
    "    texto = re.sub(r'[áàäâ]', 'a', texto)\n",
    "    texto = re.sub(r'[éèëê]', 'e', texto)\n",
    "    texto = re.sub(r'[íìïî]', 'i', texto)\n",
    "    texto = re.sub(r'[óòöô]', 'o', texto)\n",
    "    texto = re.sub(r'[úùüû]', 'u', texto)\n",
    "    texto = re.sub(r'[ý]', 'y', texto)\n",
    "    texto = re.sub(r'[ñ]', 'n', texto)\n",
    "    \n",
    "    # Eliminar caracteres especiales y números, dejando solo letras y espacios\n",
    "    texto = re.sub(r'[^a-z\\s]', '', texto)\n",
    "    \n",
    "    return texto\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras:109261\n",
      "Total de palabras no repetidas:13105\n"
     ]
    }
   ],
   "source": [
    "# Crear un diccionario para almacenar las palabras y sus frecuencias\n",
    "\n",
    "#Aplicar la limpieza al texto completo y separa en palabras\n",
    "palabras = limpiar_texto(texto).split()\n",
    "\n",
    "#Definir arreglo de vocabulario\n",
    "vocabulario = {}\n",
    "\n",
    "# Analiza cada palabra para igresarla al vocabulario y si ya existe aumenta el contador para conocer su frecuencia\n",
    "for palabra in palabras:\n",
    "    if palabra in vocabulario:\n",
    "        vocabulario[palabra] += 1\n",
    "    else:\n",
    "        vocabulario[palabra] = 1\n",
    "\n",
    "# Mostrar el diccionario resultante\n",
    "print(\"Total de palabras:\" + str(len(palabras)))\n",
    "print(\"Total de palabras no repetidas:\" + str(len(set(vocabulario))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordena por frecuencia\n",
    "valores_ord = sorted(vocabulario.items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('de', 5325), ('la', 3918), ('que', 3818), ('el', 3394), ('y', 3123), ('en', 2836), ('a', 2489), ('se', 1681), ('un', 1601), ('no', 1498), ('los', 1353), ('una', 1319), ('su', 1245), ('por', 936), ('las', 935), ('con', 924), ('habia', 858), ('del', 813), ('al', 756), ('es', 749), ('lo', 719), ('le', 667), ('era', 650), ('como', 572), ('mas', 513), ('para', 504), ('senor', 447), ('esta', 414), ('pero', 372), ('hombre', 363), ('si', 358), ('sus', 344), ('todo', 327), ('me', 326), ('sin', 311), ('obispo', 286), ('dijo', 281), ('cuando', 274), ('estaba', 273), ('sobre', 269), ('dos', 264), ('este', 261), ('aquel', 253), ('mi', 244), ('ya', 229), ('hacia', 219), ('yo', 218), ('esto', 218), ('madeleine', 214), ('tenia', 212), ('jean', 200), ('ha', 199), ('fantine', 194), ('valjean', 192), ('aquella', 190), ('hay', 186), ('he', 182), ('ser', 181), ('muy', 178), ('javert', 175), ('nada', 174), ('mismo', 173), ('o', 164), ('os', 163), ('poco', 158), ('tan', 158), ('bien', 157), ('ni', 156), ('ella', 155), ('quien', 151), ('alcalde', 149), ('vez', 148), ('despues', 146), ('fue', 145), ('todos', 141), ('puerta', 137), ('anos', 136), ('hubiera', 133), ('cual', 133), ('donde', 131), ('dios', 130), ('mujer', 127), ('momento', 125), ('tiempo', 124), ('sido', 124), ('casa', 123), ('son', 121), ('aqui', 120), ('noche', 119), ('hecho', 118), ('tres', 115), ('dia', 114), ('luego', 113), ('cabeza', 113), ('decir', 112), ('voz', 111), ('alli', 107), ('ojos', 107), ('monsenor', 105), ('aun', 105)]\n"
     ]
    }
   ],
   "source": [
    "#imprimir la 100 palabras con mayor número de repeticiones\n",
    "print(valores_ord[0:100])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('reprobo', 1), ('emocionantes', 1), ('florecer', 1), ('palidos', 1), ('fulgor', 1), ('sepultura', 1), ('recluyo', 1), ('lugares', 1), ('conversaciones', 1), ('bejean', 1), ('bojean', 1), ('boujean', 1), ('almibarado', 1), ('rehusado', 1), ('perillanes', 1), ('sucia', 1), ('abundaron', 1), ('abonada', 1), ('drapeau', 1), ('blanc', 1), ('ensenara', 1), ('partidarios', 1), ('despavorida', 1), ('reflexionando', 1), ('puestos', 1), ('velaban', 1), ('colgo', 1), ('esperara', 1), ('inconscientemente', 1), ('ensimismamiento', 1), ('candela', 1), ('boquiabierta', 1), ('retenido', 1), ('embargada', 1), ('barrote', 1), ('guardaria', 1), ('maestra', 1), ('lateral', 1), ('registrado', 1), ('conducian', 1), ('peldanos', 1), ('deshecha', 1), ('huella', 1), ('penultima', 1), ('obtuvo', 1), ('envolvio', 1), ('embalaba', 1), ('mordiendo', 1), ('comprobado', 1), ('migas', 1), ('encontradas', 1), ('pesquisas', 1), ('enrojecidos', 1), ('violencias', 1), ('integros', 1), ('entranas', 1), ('obligan', 1), ('doblar', 1), ('leerlo', 1), ('servira', 1), ('sonidos', 1), ('inarticulados', 1), ('persiguiendome', 1), ('turbaria', 1), ('alboroto', 1), ('murmullos', 1), ('protestas', 1), ('ambiente', 1), ('respirable', 1), ('integramente', 1), ('objecion', 1), ('correcto', 1), ('amuralladas', 1), ('retirarse', 1), ('quedarse', 1), ('aventurar', 1), ('desfallecer', 1), ('insista', 1), ('evadido', 1), ('mintio', 1), ('seguidas', 1), ('holocausto', 1), ('valga', 1), ('reparo', 1), ('singularidad', 1), ('bujia', 1), ('marchando', 1), ('brumas', 1), ('alejaba', 1), ('devuelta', 1), ('posiblemente', 1), ('reservar', 1), ('simplifico', 1), ('estricto', 1), ('enterrada', 1), ('gratuito', 1), ('cementerio', 1), ('encontrados', 1), ('sufrio', 1), ('promiscuidad', 1)]\n"
     ]
    }
   ],
   "source": [
    "#imprimir la 100 palabras con menor número de repeticiones\n",
    "print(valores_ord[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Guardar el vocabulario en un archivo parquet\n",
    "ds_words = pd.DataFrame(valores_ord, columns=['word', 'count'])\n",
    "ds_words.to_parquet('MiserableVocabulary.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
