{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Name = txtProc_BagOTrigrams.ipynb\n",
    "\n",
    "Do Txt Processing under Keras TF, specifically, do sentiment analysis using the\n",
    "bag of words approach\n",
    "\n",
    "Last tested           4/12/2024\n",
    "OS                    Ubuntu 22.04.4  LTS\n",
    "Python                3.10.6\n",
    "TF Version            2.16.1\n",
    "Keras version         2.16.1\n",
    "numpy version         1.26.4\n",
    "Number of GPUs        1\n",
    "nVidia Driver         550.54.15\n",
    "CUDA Version:          12.4  \n",
    "\n",
    "IMDB data ise used, from \n",
    "\n",
    "\n",
    "cd ~Data\n",
    "mkdir IMDB\n",
    "cd IMDB\n",
    "in path ~/Data/IMDB :\n",
    "curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "tar -xf aclImdb_v1.tar.gz\n",
    "\n",
    "The commands above create the following directory structure \n",
    "aclImdb/\n",
    "...train/\n",
    "......pos/\n",
    "......neg/\n",
    "...test/\n",
    "......pos/\n",
    "......neg/\n",
    "    \n",
    "The data was used as part of the paper \"Learning Word Vectors for Sentiment Analysis\" by Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and  Christopher Potts, all from Stanford, 2011.\n",
    "\n",
    "The \"readme.txt\" file in the main directory describes the organization of the data\n",
    "files, and the meainig of the names in the files.\n",
    "\n",
    "There are 25K text files for training and 25K for testing. The train/pos/ directory contains 12.5k text files, each of which contains positive-sentiment movie reviews Similarly, there are 12.5K negative-sentiment reviews located at the “neg” directory.\n",
    "\n",
    "The test/pos and test/neg directories follow the same idea. \n",
    "\n",
    "Before creating and running the model, a validation was created (once) by using  5K files from the training set, resulting in a change in size of the training as 25k - 5k = 20k.\n",
    "\n",
    "The unsup directory contains \"unsupervised\" data, which is not used.\n",
    "\n",
    "The code here uses different vectorization which is different from the code in bag_of_tokens. Here the TextVectorization specifies an additional argument ngrams=2, and it gives a different name to the ngrams produced.\n",
    "\n",
    "Once this is done, I think the code flows in the same way as in bag_of_tokens\n",
    "The model contains 16 (dense) layers. The activation function is \"relu\" and uses an input of size max_tokens=20000. \n",
    "\n",
    "Once these steps are done the model is created and when it runs, the validation accuracy is 90% so we went from 88% using a bag of tokens to 90% using 2grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 23:25:53.223933: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1741476353.236666    4765 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1741476353.240400    4765 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-08 23:25:53.254386: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version    2.18.0\n",
      "TF Path       /usr/local/lib/python3.11/site-packages/keras/api/_v2\n",
      "Keras version  3.8.0\n",
      "numpy version  2.0.2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from logging import logProcesses\n",
    "import os, pathlib, shutil, random\n",
    "from platform import python_branch\n",
    "from syslog import LOG_SYSLOG\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "print(\"TF Version   \", tf.__version__)\n",
    "print(\"TF Path      \", tf.__path__[0])\n",
    "print(\"Keras version \", keras.__version__)\n",
    "print(\"numpy version \", np.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "create_validation_set_fn()\n",
    "\n",
    "Take 20% of the training set for validation. The training set gives away 5k files,\n",
    "therefore after this function executes, the training set will contain 25k-5k=20k.\n",
    "Before running this function it is a good idea to remove the directory (if present).\n",
    "\n",
    "Last time I used this code was with  ./exerciseIMDB/aclImdb/val\n",
    "and its content. \n",
    "\n",
    "DO NOT RUN THIS CODE if the val data is already created\n",
    "\"\"\" \n",
    "def create_validation_set_fn() :\n",
    "  base_dir = pathlib.Path(\"./exerciseIMDB/aclImdb\")\n",
    "  val_dir = base_dir / \"val\"\n",
    "  train_dir = base_dir / \"train\"\n",
    "\n",
    "  for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1377).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[ -num_val_samples: ]\n",
    "    for fname in val_files :\n",
    "      shutil.move( train_dir / category /fname, val_dir / category / fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_data_sets_fn()\n",
    "\n",
    "trn_ds, tst_ds, val_ds = create_data_sets_fn( strBaseDir )\n",
    "  \n",
    "Rceive a string that contains a base directory where the raw data is stored.\n",
    "Return three data sets, for training, testing and validation\n",
    "  i.e., (trn, tst, val)\n",
    "\"\"\"\n",
    "def create_data_sets_fn( strBaseDir ) :\n",
    "    batch_size = 32\n",
    "    base_dir = pathlib.Path( strBaseDir )\n",
    "    train_ds =  keras.utils.text_dataset_from_directory( base_dir / \"train\", batch_size=batch_size )\n",
    "    val_ds = keras.utils.text_dataset_from_directory( base_dir / \"val\", batch_size=batch_size )\n",
    "    test_ds = keras.utils.text_dataset_from_directory( base_dir / \"test\", batch_size=batch_size )\n",
    "\n",
    "    # verify by printing that the 3 data sets were created correctly\n",
    "    for inputs, targets in train_ds:\n",
    "         print(\"inputs.shape:\", inputs.shape)\n",
    "         print(\"inputs.dtype:\", inputs.dtype)\n",
    "         print(\"targets.shape:\", targets.shape)\n",
    "         print(\"targets.dtype:\", targets.dtype)\n",
    "         print(\"inputs[0]:\", inputs[0])\n",
    "         print(\"targets[0]:\", targets[0])\n",
    "         break\n",
    "    \n",
    "    return train_ds, test_ds, val_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "textvectorization_preprocessing_fn( train_ds, test_ds, val_ds)\n",
    "\n",
    "Get the three data sets as arguments to limit the vocabulary to the 20K\n",
    "most frequent words in the data set. \n",
    "\n",
    "Note that the argument to textVectorization sets the data as bigrams\n",
    "\n",
    " As part of ending, the function\n",
    "returns the items as shown below\n",
    "\n",
    "     return binary_2gram_train_ds, binary_2gram_train_ds, binary_2gram_train_ds\n",
    "\"\"\"\n",
    "def textvectorization_preprocessing_fn( train_ds, test_ds, val_ds ) :\n",
    "  text_vectorization = TextVectorization( ngrams=3, \n",
    "                                         max_tokens=20000, output_mode=\"multi_hot\",)\n",
    "    \n",
    "  # prepare a data set that yields only fields raw text input (no labels)\n",
    "  text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "\n",
    "  text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "  # prepare processed versions for training, validation, testing. Use 8 cores\n",
    "  binary_3gram_train_ds = train_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_3gram_test_ds  = test_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_3gram_val_ds   = val_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "\n",
    "  for inputs, targets in  binary_3gram_train_ds :\n",
    "    print(\"inputs.shape:\",  inputs.shape)\n",
    "    print(\"inputs.dtype:\",  inputs.dtype)\n",
    "    print(\"targets.dtype:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\",     inputs[0])\n",
    "    print(\"targets[0]:\",    targets[0])\n",
    "    break\n",
    "\n",
    "  return binary_3gram_train_ds, binary_3gram_test_ds, binary_3gram_val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_model_fn()\n",
    "get_model_fn( max_tokens=20000, hidden_dim=16)\n",
    "\n",
    "Receive the max number of tokes and the number of layers.\n",
    "Use those parameters to create a dense model of the given dimension.\n",
    "The model's activation is relu      \n",
    "      \n",
    "\"\"\"\n",
    "def get_model_fn( max_tokens=20000, hidden_dim=16) :\n",
    "  inputs = keras.Input(shape=(max_tokens,))\n",
    "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70000 files belonging to 3 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1741476367.317476    4765 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1278 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "inputs.shape: (32,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'The spoilers in this review are offered as a public service, because the only way to enjoy this costume melodrama is to know that our protagonist, the Lady Barbara Skelton, gets raped and gunned down in the end. And not a moment too soon. I\\'d have shot the screen myself but I was afraid I\\'d hit James Mason.<br /><br />The original 1943 novel, called \"The Life and Death of the Wicked Lady Skelton\" (I guess people didn\\'t whine about spoilers back then), was written by a woman, an English navy brat who was either troubled or cynical or both. Her heroine is devastatingly beautiful, and the author seems to think that if you have beauty, nothing else matters. But other things do matter, such as the fact that Lady Barbara\\'s immediate and only response when someone gets in her way is homicide. She murders three men in five attempts. A serial femme fatale, she\\'s got a case of dissocial personality disorder that should have landed her in either Bedlam or Newgate. <br /><br />Lockwood plays her as a narcissistic vamp, wearing so much makeup that I thought of her as a Restoration-era Joan Rivers (or a restoration-era Joan Rivers, ha!). Yet Lady B. is irresistible to all three principal male characters-- Michael Rennie, James Mason, and Griffith Jones, all of whom do good work, as does Patricia Roc. Of course, all three admirers realize in short order what a psychotic bitch Barbara is, but the plot keeps them all in her orbit until one of them finally does gun her down - accidentally, in what is meant to be either irony or just desserts. Given the dramatic death scene with a boom lifting the camera out through the windows and heavenward, I presume we\\'re meant to give a damn about her death. But hers is the first corpse we don\\'t care about.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-08 23:26:46.356806: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs.shape: (32, 20000)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.dtype: (32,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m320,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1741476435.701389    5161 service.cc:148] XLA service 0x719e140053b0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1741476435.701469    5161 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060, Compute Capability 8.6\n",
      "2025-03-08 23:27:15.716371: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1741476435.776133    5161 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2025-03-08 23:27:15.942793: W external/local_xla/xla/service/gpu/nvptx_compiler.cc:930] The NVIDIA driver's CUDA version is 12.4 which is older than the PTX compiler version 12.5.82. Because the driver is older than the PTX compiler version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
      "I0000 00:00:1741476436.123721    5161 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 4ms/step - accuracy: 0.1438 - loss: -188.9910 - val_accuracy: 0.5000 - val_loss: 1287.6595\n",
      "Epoch 2/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -2268.1406 - val_accuracy: 0.5000 - val_loss: 4803.0293\n",
      "Epoch 3/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -6913.8940 - val_accuracy: 0.5000 - val_loss: 10552.8965\n",
      "Epoch 4/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -13937.5049 - val_accuracy: 0.5000 - val_loss: 18514.7441\n",
      "Epoch 5/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -23658.9883 - val_accuracy: 0.5000 - val_loss: 28712.6172\n",
      "Epoch 6/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -35752.0039 - val_accuracy: 0.5000 - val_loss: 41109.7070\n",
      "Epoch 7/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -49775.1680 - val_accuracy: 0.5000 - val_loss: 55682.8945\n",
      "Epoch 8/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -67052.1797 - val_accuracy: 0.5000 - val_loss: 72517.4297\n",
      "Epoch 9/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -87366.8516 - val_accuracy: 0.5000 - val_loss: 91595.7031\n",
      "Epoch 10/10\n",
      "\u001b[1m2188/2188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.1435 - loss: -109122.5156 - val_accuracy: 0.5000 - val_loss: 112910.1953\n",
      "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.5019 - loss: 1276.4314\n",
      "Test acc: 0.500\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "      jev_main_fn()\n",
    "\n",
    "Start the execution of the code in this file\n",
    "\n",
    "\"\"\"\n",
    "def jev_main_fn() :\n",
    "  strBaseDir  = \"./exerciseIMDB/aclImdb\"\n",
    "\n",
    "  # call create_validation_set_fn() once to create 5K files in two directories (pos, neg)\n",
    "  # each with 2.5 k files. The 5K files are taken away from the train set, therefore the\n",
    "  # size of the training set will be 25k - 5k = 20K \n",
    "  #\n",
    "  #  create_validation_set_fn() \n",
    "  #\n",
    "\n",
    "  train_ds, test_ds, val_ds = create_data_sets_fn( strBaseDir )\n",
    "  binary_3gram_train_ds, binary_3gram_test_ds, binary_3gram_val_ds = textvectorization_preprocessing_fn( train_ds, test_ds, val_ds )\n",
    "\n",
    "  model = get_model_fn()\n",
    "  model.summary()\n",
    "  callbacks = [ keras.callbacks.ModelCheckpoint(\"./exerciseIMDB/aclImdb/Playground/binary_3gram.keras\", save_best_only=True) ]\n",
    "\n",
    "  model.fit(  binary_3gram_train_ds.cache(), \n",
    "              validation_data= binary_3gram_val_ds.cache(),\n",
    "              epochs=10, callbacks=callbacks)\n",
    "  model=keras.models.load_model(\"./exerciseIMDB/aclImdb/Playground/binary_3gram.keras\")\n",
    "  print(f\"Test acc: {model.evaluate(binary_3gram_test_ds)[1]:.3f}\")\n",
    "\n",
    "  print(\"Done\")\n",
    "\n",
    "#### LET\"S GO ! ! ! ! \n",
    "jev_main_fn()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
