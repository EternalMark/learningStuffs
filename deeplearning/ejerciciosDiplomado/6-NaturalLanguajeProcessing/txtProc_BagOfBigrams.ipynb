{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "File Name = txtProc_BagOfBigrams.ipynb\n",
    "\n",
    "+ Do Txt Processing under Keras TF, specifically, do sentiment analysis using the bag of words approach.\n",
    "\n",
    "+ The IMDB data is used, from \n",
    "\n",
    "```\n",
    "cd ~Data\n",
    "mkdir IMDB\n",
    "cd IMDB\n",
    "in path ~/Data/IMDB :\n",
    "curl -O https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
    "tar -xf aclImdb_v1.tar.gz\n",
    "\n",
    "The commands above create the directory structure \n",
    "aclImdb/\n",
    "...train/\n",
    "......pos/\n",
    "......neg/\n",
    "...test/\n",
    "......pos/\n",
    "......neg/\n",
    "```\n",
    "    \n",
    "+ The data was originally used as part of the paper \"Learning Word Vectors for Sentiment Analysis\" by Andrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and  Christopher Potts, all from Stanford, 2011.\n",
    "\n",
    "+ The \"readme.txt\" file in the main directory describes the organization of the data files, and the meainig of the names in the files.\n",
    "\n",
    "+ There are 25K text files for training and 25K for testing. The train/pos/ directory contains 12.5k text files, each of which contains positive-sentiment movie reviews Similarly, there are 12.5K negative-sentiment reviews located at the “neg” directory.\n",
    "\n",
    "+ The test/pos and test/neg directories follow the same idea. \n",
    "\n",
    "+ Before creating and running the model, a validation was created (once) by using  5K files from the training set, resulting in a change in size of the training as 25k - 5k = 20k.\n",
    "\n",
    "+ The unsup directory contains \"unsupervised\" data, which is not used.\n",
    "\n",
    "+ The code here uses different vectorization which is different from the code in bag_of_tokens. Here the TextVectorization specifies an additional argument ngrams=2, and it gives a different name to the ngrams produced.\n",
    "\n",
    "+ Once this is done, I think the code flows in the same way as in bag_of_tokens\n",
    "The model contains 16 (dense) layers. The activation function is \"relu\" and uses an input of size max_tokens=20000. \n",
    "\n",
    "+ Once these steps are done the model is created and when it runs, the validation accuracy is 90% so we went from 88% using a bag of tokens to 90% using 2grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF Version    2.18.0\n",
      "TF Path       /usr/local/lib/python3.11/site-packages/keras/api/_v2\n",
      "Keras version  3.8.0\n",
      "numpy version  2.0.2\n",
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import string\n",
    "\n",
    "from logging import logProcesses\n",
    "import os, pathlib, shutil, random\n",
    "from platform import python_branch\n",
    "from syslog import LOG_SYSLOG\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import TextVectorization\n",
    "\n",
    "\n",
    "print(\"TF Version   \", tf.__version__)\n",
    "print(\"TF Path      \", tf.__path__[0])\n",
    "print(\"Keras version \", keras.__version__)\n",
    "print(\"numpy version \", np.__version__)\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "create_validation_set_fn()\n",
    "\n",
    "Take 20% of the training set for validation. The training set gives away 5k files,\n",
    "therefore after this function executes, the training set will contain 25k-5k=20k.\n",
    "Before running this function it is a good idea to remove the directory (if present).\n",
    "\n",
    "Last time I used this code was with  ./exerciseIMDB/aclImdb/val\n",
    "and its content. \n",
    "\n",
    "DO NOT RUN THIS CODE if the val data is already created\n",
    "\"\"\" \n",
    "def create_validation_set_fn():\n",
    "  base_dir = pathlib.Path(\"./exerciseIMDB/aclImdb\")\n",
    "  val_dir = base_dir / \"val\"\n",
    "  train_dir = base_dir / \"train\"\n",
    "\n",
    "  for category in (\"neg\", \"pos\"):\n",
    "    os.makedirs(val_dir / category)\n",
    "    files = os.listdir(train_dir / category)\n",
    "    random.Random(1377).shuffle(files)\n",
    "    num_val_samples = int(0.2*len(files))\n",
    "    val_files = files[ -num_val_samples: ]\n",
    "    for fname in val_files :\n",
    "      shutil.move( train_dir / category /fname, val_dir / category / fname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "create_data_sets_fn()\n",
    "\n",
    "trn_ds, tst_ds, val_ds = create_data_sets_fn( strBaseDir )\n",
    "  \n",
    "Rceive a string that contains a base directory where the raw data is stored.\n",
    "Return three data sets, for training, testing and validation\n",
    "  i.e., (trn, tst, val)\n",
    "\"\"\"\n",
    "def create_data_sets_fn( strBaseDir,batch_size) :\n",
    "    base_dir = pathlib.Path( strBaseDir )\n",
    "    train_ds =  keras.utils.text_dataset_from_directory( base_dir / \"train\", batch_size=batch_size )\n",
    "    val_ds = keras.utils.text_dataset_from_directory( base_dir / \"val\", batch_size=batch_size )\n",
    "    test_ds = keras.utils.text_dataset_from_directory( base_dir / \"test\", batch_size=batch_size )\n",
    "\n",
    "    # verify by printing that the 3 data sets were created correctly\n",
    "    for inputs, targets in train_ds:\n",
    "         print(\"inputs.shape:\", inputs.shape)\n",
    "         print(\"inputs.dtype:\", inputs.dtype)\n",
    "         print(\"targets.shape:\", targets.shape)\n",
    "         print(\"targets.dtype:\", targets.dtype)\n",
    "         print(\"inputs[0]:\", inputs[0])\n",
    "         print(\"targets[0]:\", targets[0])\n",
    "         break\n",
    "    \n",
    "    return train_ds, test_ds, val_ds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "textvectorization_preprocessing_fn( train_ds, test_ds, val_ds)\n",
    "\n",
    "Get the three data sets as arguments to limit the vocabulary to the 20K\n",
    "most frequent words in the data set. \n",
    "\n",
    "Note that the argument to textVectorization sets the data as bigrams\n",
    "\n",
    " As part of ending, the function returns the items as shown below\n",
    "\n",
    "     return binary_2gram_train_ds, binary_2gram_train_ds, binary_2gram_train_ds\n",
    "\"\"\"\n",
    "def textvectorization_preprocessing_fn( train_ds, test_ds, val_ds ) :\n",
    "  text_vectorization = TextVectorization( ngrams=2, \n",
    "                                         max_tokens=20000, output_mode=\"multi_hot\",)\n",
    "    \n",
    "  # prepare a data set that yields only fields raw text input (no labels)\n",
    "  text_only_train_ds = train_ds.map(lambda x, y: x)\n",
    "\n",
    "  text_vectorization.adapt(text_only_train_ds)\n",
    "\n",
    "  # prepare processed versions for training, validation, testing. Use 8 cores\n",
    "  binary_2gram_train_ds = train_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_2gram_test_ds  = test_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "  binary_2gram_val_ds   = val_ds.map ( lambda x, y: (text_vectorization(x), y), num_parallel_calls=8)\n",
    "\n",
    "  for inputs, targets in  binary_2gram_train_ds :\n",
    "    print(\"inputs.shape:\",  inputs.shape)\n",
    "    print(\"inputs.dtype:\",  inputs.dtype)\n",
    "    print(\"targets.dtype:\", targets.shape)\n",
    "    print(\"targets.dtype:\", targets.dtype)\n",
    "    print(\"inputs[0]:\",     inputs[0])\n",
    "    print(\"targets[0]:\",    targets[0])\n",
    "    break\n",
    "\n",
    "  return binary_2gram_train_ds, binary_2gram_test_ds, binary_2gram_val_ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "get_model_fn()\n",
    "get_model_fn( max_tokens=20000, hidden_dim=16)\n",
    "\n",
    "Receive the max number of tokes and the number of layers.\n",
    "Use those parameters to create a dense model of the given dimension.\n",
    "The model's activation is relu      \n",
    "      \n",
    "\"\"\"\n",
    "def get_model_fn( max_tokens=20000, hidden_dim=16) :\n",
    "  inputs = keras.Input(shape=(max_tokens,))\n",
    "  x = layers.Dense(hidden_dim, activation=\"relu\")(inputs)\n",
    "  x = layers.Dropout(0.5)(x)\n",
    "  outputs = layers.Dense(1, activation=\"sigmoid\") (x)\n",
    "  model = keras.Model(inputs, outputs)\n",
    "  model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "  return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70000 files belonging to 3 classes.\n",
      "Found 5000 files belonging to 2 classes.\n",
      "Found 25000 files belonging to 2 classes.\n",
      "inputs.shape: (1024,)\n",
      "inputs.dtype: <dtype: 'string'>\n",
      "targets.shape: (1024,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor(b'Normally, I am a pretty generous critic, but in the case of this film I have to say it was incredibly bad. I am stunned by how positive most reviews seem to be.<br /><br />There were some gorgeous shots, but it\\'s too bad they were wasted on this sinkhole of a movie. It might have worked if \"Daggers\" was purely an action flick and not a romance, but unfortunately the film is built around an empty love triangle. There is no chemistry between either of the couples, whatever exists between Mei and her men seems to be more lust than love, and for the most part the dialogue is just silly. This may be just a problem with translation, but the frequent usage of the word \"flirt\" in particular reminded me of 8th grade, not head-over-heels, together forever, worth-dying-for love; I also felt we were beat over the head with the wind metaphor. The audience is given very little about the characters to really care about, and therefore very little emotional investment in the movie as a whole. I was wishing for a remote control to fast forward, I was slumped in my seat ready to snore, but mostly I just cringed a lot.<br /><br />*******spoiler*****<br /><br />Now, the icing on the cake. Or rather, adding insult to injury. The ending was truly one of the most horrible, laughable ones I have ever seen. The boys are having their stag fight and screaming and yelling and hacking at each other. Oh, and then it starts to snow. Randomly. Oh, and then Mei (dagger embedded in heart) suddenly pops up out of the weeds. Then she throws a dagger that seems to take about 5 minutes to reach it\\'s destination, even slowing conveniently midscreen to hit a tiny blood droplet. Wow, cool.<br /><br />Well, then Mei dies finally I guess because she threw the dagger that was lodged in her chest and bled to death. Jin sings, sobs, holds her body close, screen goes blank. I, and the people surrounding me, are chuckling. Not a good sign.<br /><br />Visually stunning, but ultimately a failure.', shape=(), dtype=string)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n",
      "inputs.shape: (1024, 20000)\n",
      "inputs.dtype: <dtype: 'int64'>\n",
      "targets.dtype: (1024,)\n",
      "targets.dtype: <dtype: 'int32'>\n",
      "inputs[0]: tf.Tensor([1 1 1 ... 0 0 0], shape=(20000,), dtype=int64)\n",
      "targets[0]: tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20000</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">320,016</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20000\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │       \u001b[38;5;34m320,016\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">320,033</span> (1.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m320,033\u001b[0m (1.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 78ms/step - accuracy: 0.1435 - loss: -5.5271 - val_accuracy: 0.5000 - val_loss: 19.5436\n",
      "Epoch 2/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -28.7393 - val_accuracy: 0.5000 - val_loss: 45.4578\n",
      "Epoch 3/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -60.1792 - val_accuracy: 0.5000 - val_loss: 78.9670\n",
      "Epoch 4/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 35ms/step - accuracy: 0.1430 - loss: -100.8684 - val_accuracy: 0.5000 - val_loss: 120.0054\n",
      "Epoch 5/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -147.8726 - val_accuracy: 0.5000 - val_loss: 168.3074\n",
      "Epoch 6/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -205.0133 - val_accuracy: 0.5000 - val_loss: 224.0835\n",
      "Epoch 7/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -270.3708 - val_accuracy: 0.5000 - val_loss: 287.1504\n",
      "Epoch 8/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -342.3329 - val_accuracy: 0.5000 - val_loss: 357.6710\n",
      "Epoch 9/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -426.6089 - val_accuracy: 0.5000 - val_loss: 435.4672\n",
      "Epoch 10/10\n",
      "\u001b[1m69/69\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - accuracy: 0.1430 - loss: -514.8015 - val_accuracy: 0.5000 - val_loss: 520.6849\n",
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.4993 - loss: 19.5500\n",
      "Test acc: 0.500\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "      jev_main_fn()\n",
    "\n",
    "Start the execution of the code in this file\n",
    "\n",
    "\"\"\"\n",
    "def jev_main_fn() :\n",
    "  strBaseDir  = \"./exerciseIMDB/aclImdb\"\n",
    "\n",
    "  # call create_validation_set_fn() once to create 5K files in two directories (pos, neg)\n",
    "  # each with 2.5 k files. The 5K files are taken away from the train set, therefore the\n",
    "  # size of the training set will be 25k - 5k = 20K \n",
    "  #\n",
    "  # create_validation_set_fn() \n",
    "  #\n",
    "\n",
    "  train_ds, test_ds, val_ds = create_data_sets_fn( strBaseDir,batch_size=1024)\n",
    "  binary_2gram_train_ds, binary_2gram_test_ds, binary_2gram_val_ds = textvectorization_preprocessing_fn( train_ds, test_ds, val_ds )\n",
    "\n",
    "  model = get_model_fn()\n",
    "  model.summary()\n",
    "  callbacks = [ keras.callbacks.ModelCheckpoint(\"./exerciseIMDB/aclImdb/Playground/binary_2gram.keras\", save_best_only=True) ]\n",
    "\n",
    "  model.fit(  binary_2gram_train_ds.cache(), \n",
    "              validation_data= binary_2gram_val_ds.cache(),\n",
    "              epochs=10, callbacks=callbacks)\n",
    "  \n",
    "  model=keras.models.load_model(\"./exerciseIMDB/aclImdb/Playground/binary_2gram.keras\")\n",
    "  print(f\"Test acc: {model.evaluate(binary_2gram_test_ds)[1]:.3f}\")\n",
    "\n",
    "  print(\"Done\")\n",
    "\n",
    "#### LET\"S GO ! ! ! ! \n",
    "jev_main_fn()\n",
    "\n",
    "# Batch 128 - 1min3.7s\n",
    "# Batch 64 - 1min21.6s\n",
    "# Batch 1024 - 52.6s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
